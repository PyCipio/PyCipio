{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd05698216558bfa99e9d0f38da36571f7d9dccffc67e29b4443301a5ed3d75bbb7",
   "display_name": "Python 3.8.5 64-bit ('CM': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "5698216558bfa99e9d0f38da36571f7d9dccffc67e29b4443301a5ed3d75bbb7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from covid19dh import covid19\n",
    "from datetime import date\n",
    "from Get_covid_data import get_data\n",
    "import pymc3 as pm\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import theano\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# import functions from fns file \n",
    "import fns as f"
   ]
  },
  {
   "source": [
    "Load covid data, create subset/new columns and plot"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "We have invested a lot of time and effort in creating COVID-19 Data Hub, please cite the following when using it:\n\n\t\u001b[1mGuidotti, E., Ardia, D., (2020), \"COVID-19 Data Hub\", Journal of Open Source Software 5(51):2376, doi: 10.21105/joss.02376.\u001b[0m\n\nA BibTeX entry for LaTeX users is\n\n\t@Article{,\n\t\ttitle = {COVID-19 Data Hub},\n\t\tyear = {2020},\n\t\tdoi = {10.21105/joss.02376},\n\t\tauthor = {Emanuele Guidotti and David Ardia},\n\t\tjournal = {Journal of Open Source Software},\n\t\tvolume = {5},\n\t\tnumber = {51},\n\t\tpages = {2376},\n\t}\n\n\u001b[33mTo hide this message use 'verbose = False'.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Get data\n",
    "data = get_data(level = 2, start = date(2020,1,1)) #can get more or less data here.\n",
    "#group_by introduce lag (new infected from commulative)\n",
    "data[\"new_infected\"] = data.groupby([\"administrative_area_level_2\"])[\"confirmed\"].diff()\n",
    "data = data[data[\"new_infected\"].notna()]\n",
    "##Create subset from 5 states\n",
    "#subset = data[data['administrative_area_level_2'].isin([\"Florida\"])]\n",
    "##Check data\n",
    "#sns.lineplot(data = data, x = \"date\", y = \"new_infected\", hue = \"administrative_area_level_2\")\n",
    "\n"
   ]
  },
  {
   "source": [
    "Prep data and create train/test split"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-68-e560b23adba9>:17: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  train['new_infected'] = scaler.fit_transform(train['new_infected'].values.reshape(-1,1))\n"
     ]
    }
   ],
   "source": [
    "# specify x, y & grouping variable in orig. data &\n",
    "# the name that will be used going forward (can be the same). \n",
    "y = \"new_infected\"\n",
    "x_old = \"date\"\n",
    "idx_old = \"administrative_area_level_2\"\n",
    "x_new = \"date_2\"\n",
    "idx_new = \"idx\"\n",
    "\n",
    "# get idx for each group (e.g. country) and zero-index for time variable (e.g. year).\n",
    "d = f.get_idx(data, idx_old, x_old, idx_new, x_new)\n",
    "\n",
    "# use test/train split function\n",
    "train, test = f.train_test(d, x_new) # check doc-string.\n",
    "\n",
    "#Scale values:\n",
    "scaler = MinMaxScaler()\n",
    "train['new_infected'] = scaler.fit_transform(train['new_infected'].values.reshape(-1,1))\n",
    "test['new_infected'] = scaler.fit_transform(test['new_infected'].values.reshape(-1,1))\n",
    "\n",
    "# we need N here as well for shape.\n",
    "N = len(np.unique(train[idx_new]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-65-1baac83fd9ff>:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  train['Col1_scaled'] = scaler.fit_transform(train['new_infected'].values.reshape(-1,1))\n"
     ]
    }
   ],
   "source": []
  },
  {
   "source": [
    "Build model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [ε, β, α, β_σ, β_μ, α_σ, α_μ]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='0' class='' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 2842 seconds.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "The rhat statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    }
   ],
   "source": [
    "# pooled model\n",
    "with pm.Model() as m1: \n",
    "    \n",
    "    # hyper-priors\n",
    "    α_μ = pm.Normal('α_μ', mu=0, sd=1)\n",
    "    α_σ = pm.HalfNormal('α_σ', 1)\n",
    "    β_μ = pm.Normal('β_μ', mu=0, sd=1)\n",
    "    β_σ = pm.HalfNormal('β_σ', sd=1)\n",
    "    \n",
    "    # priors\n",
    "    α = pm.Normal('α', mu=α_μ, sd=α_σ, shape=N)\n",
    "    β = pm.Normal('β', mu=β_μ, sd=β_σ, shape=N)\n",
    "    ε = pm.HalfCauchy('ε', 1)\n",
    "    \n",
    "    # containers \n",
    "    x_ = pm.Data('m1_x', train[x_new].values) #Year_ as data container (can be changed). \n",
    "    idx_ = pm.Data('m1_idx', train[idx_new].values)\n",
    "    \n",
    "    y_pred = pm.Normal('y_pred',\n",
    "                       mu=α[idx_] + β[idx_] * x_,\n",
    "                       sd=ε, observed=train[y].values)\n",
    "    \n",
    "    # trace \n",
    "    m1_trace = pm.sample(2000, return_inferencedata = True,\n",
    "                        target_accept = .99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check trace\n",
    "az.plot_trace(m1_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posterior predictive on new data. \n",
    "predictions = f.pp_test(\n",
    "    m1, \n",
    "    m1_trace, \n",
    "    {'m1_x': test[x_new].values, 'm1_idx': test[idx_new].values},\n",
    "    params = [\"α\", \"β\", \"y_pred\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot posterior predictive on new data. \n",
    "f.plot_pp(predictions, train, test, d, x_new, y, idx_old)"
   ]
  }
 ]
}