---
title: "Untitled"
output: html_document
---

Load packages and stuff

```{r}

setwd("~/DataScience/w8")
pacman::p_load(tidyverse, fpp3, tsibble, feasts)

```

Exercise 1 - Time Series Features
1. In the PBS data (data from pharmacies), calculate which series has the highest mean value of Cost
a. Plot it.
b. Should we do an additive or multiplicative decomposition of this series?
2. Calculate STL features of Costs.
a. Which series shows strongest and weakest seasonality? Plot them.
b. Which series are most and least trended? Plot them.

```{r}



```


Exercise 2 - The Forecaster’s Toolbox
1. Produce and plot forecasts for the following series using whichever of MEAN(y), NAIVE(y), SNAIVE(y)
or RW(y ~ drift()) is more appropriate in each case. I.e. plot the time series and inspect it to see which
method you believe is most appropriate:
• Australian Population (global_economy)
• Lambs in New South Wales (aus_livestock)

```{r}

```


2. Perform residual diagnostic checks of your models.
• Were you able to capture all information?
• Do the residuals look like white noise; do they display autocorrelation?

```{r}

```


3. Divide the hh_budget dataset into a training and test set, by withholding the last four years as test data.

a. Fit all the appropriate benchmark models (those mentioned in 1) for household Wealth on the
training data, and forecast on the test data.
b. Calculate the performance of your forecasts. Which method performs best?
c. Check the residuals of the best model for each country. Do they resemble white noise?
d. Choose one of the countries (Australia/Canada/Japan/USA) and see if you can beat the benchmarks
you just made using TSLM. Experiment with trend(), season() and knots.

```{r}

# read the data 
d <- hh_budget %>%
  glimpse()

# write this data set
write_csv(d, "hh_budget.csv")

# test and train split 
test <- d %>%
  filter(Year >= 2012)

train <- d %>%
  filter(Year < 2012)

# fit baseline models 
# not seasonal?
hh_fit <- train %>%
  model(
    Mean = MEAN(Wealth),
    Naive = NAIVE(Wealth),
    #sNAIVE = SNAIVE(Wealth),
    Drift = RW(Wealth ~ drift())
  )

# predict
hh_pred <- hh_fit %>% forecast(h = 5)
hh_pred

# plot manual 
pacman::p_load(GGally, ggthemes, ggfortify)

## make something like this work manually. 
hh_pred %>%
  filter(Country == "Canada") %>%
  ggplot() + 
  geom_line(aes(x = Year, y = .mean, color = .model)) +
  geom_line(aes(x = d %>% 
                  filter(Country == "Canada") %>%
                  pull(Year),
                y = d %>%
                  filter(Country == "Canada") %>%
                  pull(Wealth)))

## put it together (do this properly without autoplot).
hh_pred %>% 
  autoplot(d, level = NULL) +
  geom_vline(xintercept = 2011, lty = 2) 


## 1. do it manually
## 2. add confidence and/or prediction intervals. 

# b.

## augment
hh_eval <- augment(hh_fit) %>%
  glimpse()

## accuracy 
eval <- accuracy(hh_pred, d) %>% 
  group_by(Country) %>% 
  slice(which.min(RMSE)) %>%
  glimpse()

# c. 

## make function
my_func <- function(df, country, variable, func, ...){
  
  df %>%
    filter(Country == country) %>%
    model(func({{variable}}, ...)) %>%
    gg_tsresiduals
  
}

## use the function
my_func(d, "Australia", Wealth, MEAN)
my_func(d, "Canada", Wealth, RW, "~ drift()")
my_func(d, "Japan", Wealth, RW, "~ drift()")
my_func(d, "USA", Wealth, MEAN)

## comp. to white noise. 

## first augment then ljung-box (more accurate)
aug_fun <- function(df, country, variable, func, ...){
  
  df %>%
    filter(Country == country) %>%
    model(func({{variable}}, ...)) %>%
    augment() %>%
    features(.innov, ljung_box, lag = 10, dof = 0)
  
}

## use the function
aug_fun(d, "Australia", Wealth, MEAN) # almost sig. diff. from white. 
aug_fun(d, "Canada", Wealth, RW, "~ drift()") # very white. 
aug_fun(d, "Japan", Wealth, RW, "~ drift()") # very white. 
aug_fun(d, "USA", Wealth, MEAN) # almost sig. diff. from white. 

# d. CH7: Japan (what w ehave to work with.)
train %>%
  filter(Country == "Japan") %>%
  ggplot() +
  geom_line(aes(x = Year, y = Wealth))

## models. 
fit_trends <- train %>%
  model(
    drift = RW(Wealth ~ drift()), #baseline
    linear = TSLM(Wealth ~ trend()),
    exponential = TSLM(log(Wealth) ~ trend()),
    piecewise = TSLM(Wealth ~ trend(knots = c(2006, 2008)))
  )

## forecast 
fc_trends <- fit_trends %>% forecast(h = 5)

## see how good it is. 
fc_trends %>% 
  filter(Country == "Japan") %>%
  autoplot(d, level = NULL) +
  geom_vline(xintercept = 2011, lty = 2) 

## accuracy ordering. (all of our models are better). 
eval <- accuracy(fc_trends, d) %>% 
  filter(Country == "Japan") %>% 
  arrange(RMSE) %>%
  select(c(.model, Country, RMSE)) %>% 
  glimpse()

```

For all countries bitch. 

```{r}

# simple plot 
simple_plot <- function(df, country){
  
  df %>%
    filter(Country == {{country}}) %>%
    ggplot() +
    geom_line(aes(x = Year, y = Wealth))
  
}

# use simple plot 
simple_plot(train, "Japan") # 2006, 2008.
simple_plot(train, "Canada") # 1998, 2002, 2006, 2008. 
simple_plot(train, "USA") # 1999, 2002, 2007, 2008. 
simple_plot(train, "Australia") # 2006, 2011. 

better_plot <- function(country, ...){

  # d. CH7: Japan (what we have to work with.)
  train %>%
    filter(Country == {{country}}) %>%
    ggplot() +
    geom_line(aes(x = Year, y = Wealth))
  
  ## models. 
  fit_trends <- train %>%
    model(
      drift = RW(Wealth ~ drift()), #baseline
      linear = TSLM(Wealth ~ trend()),
      exponential = TSLM(log(Wealth) ~ trend()),
      piecewise = TSLM(Wealth ~ trend(knots = c(...)))
    )
  
  ## forecast 
  fc_trends <- fit_trends %>% forecast(h = 5)
  
  ## see how good it is. 
  fc_trends %>% 
    filter(Country == {{country}}) %>%
    autoplot(d, level = NULL) +
    geom_vline(xintercept = 2011, lty = 2) 

}
better_stats <- function(country, ...){
  # d. CH7: Japan (what we have to work with.)
  train %>%
    filter(Country == {{country}}) %>%
    ggplot() +
    geom_line(aes(x = Year, y = Wealth))
  
  ## models. 
  fit_trends <- train %>%
    model(
      drift = RW(Wealth ~ drift()), #baseline
      linear = TSLM(Wealth ~ trend()),
      exponential = TSLM(log(Wealth) ~ trend()),
      piecewise = TSLM(Wealth ~ trend(knots = c(...)))
    )
  
  ## forecast 
  fc_trends <- fit_trends %>% forecast(h = 5)
  
  ## accuracy ordering. (all of our models are better). 
  eval <- accuracy(fc_trends, d) %>% 
    filter(Country == {{country}}) %>% 
    arrange(RMSE) %>%
    select(c(.model, Country, RMSE)) %>% 
    glimpse()
  
  return(eval)
}

# plots
better_plot("Japan", 2006, 2008)
better_plot("Canada", 1998, 2002, 2006, 2008)
better_plot("USA", 1999, 2002, 2007, 2008)
better_plot("Australia", 2006, 2011)

# stats
better_stats("Japan", 2006, 2008) #linear 
better_stats("Canada", 1998, 2002, 2006, 2008) #piecewise
better_stats("USA", 1999, 2002, 2007, 2008) #piecewise
better_stats("Australia", 2006, 2011) #exponential

```

4. Divide the Australian takeaway food turnover (aus_retail) into a training and test set by withholding
the last four years as test data.
a. Fit all the appropriate benchmark models as well as a TSLM on the training data using time series
cross validation and evaluate their performance.
b. Train the same models on the full training data and calculate the performance on the test data.
How do the two methods compare in terms of performance measures?

```{r}

## a.
# new data 
d <- aus_retail %>%
  mutate(State = as_factor(State)) %>% 
  glimpse()

# train/test split 
test <- d %>% 
  filter(State == "Australian Capital Territory",
         Industry == "Cafes, restaurants and catering services") %>%
  filter_index("2015 Jan" ~ "2018 Dec")

train <- d %>%
  filter(State == "Australian Capital Territory",
         Industry == "Cafes, restaurants and catering services") %>%
  filter_index(. ~ "2014 Dec")

## b.
# fit models 
cross_val <- train %>%
  stretch_tsibble(.init = 12, .step = 12) %>%
  relocate(Month, State, .id)

# TSCV accuracy
cross_val %>%
  model(
    drift = RW(Turnover ~ drift()),
    exponential = TSLM(log(Turnover) ~ trend())) %>%
  forecast(h = 1) %>%
  accuracy(d)

# Training set accuracy
d_sub <- d %>%
  filter(State == "Australian Capital Territory",
         Industry == "Cafes, restaurants and catering services")

d_sub %>%
  model(
    drift = RW(Turnover ~ drift()),
    exponential = TSLM(log(Turnover) ~ trend())) %>%
  accuracy()

## is time the breaker of all wills?
fc <- cross_val %>%
  model(RW(Turnover ~ drift())) %>%
  forecast(h = 12) %>%
  group_by(.id) %>%
  mutate(h = row_number()) %>%
  ungroup()

## using it. 
fc %>%
  accuracy(d_sub, by = c("h", ".model")) %>%
  ggplot(aes(x = h, y = RMSE)) +
  geom_point()

```

close. 
